{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec24412",
   "metadata": {},
   "source": [
    "# whisper-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7dcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('small_predictions_and_labels.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2260820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('small_predictions_and_labels.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc43ed",
   "metadata": {},
   "source": [
    "# whisper-small-chinese-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5042b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('predictions_and_labels_small-chinese_base.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('predictions_and_labels_small-chinese_base.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7429d7",
   "metadata": {},
   "source": [
    "# Whisper-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'predictions_and_labels_medium.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d8195",
   "metadata": {},
   "source": [
    "# Whisper-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7dcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'predictions_and_labels_large.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497874a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855b30a",
   "metadata": {},
   "source": [
    "# wav2vec2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'predictions_and_labels_wav2vec2.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ecad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d82af9",
   "metadata": {},
   "source": [
    "# hubert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'predictions_and_labels_hubert.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a77f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74339d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "songcw",
   "language": "python",
   "name": "songcw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
