{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec24412",
   "metadata": {},
   "source": [
    "# whisper-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7dcf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Precision: [0.3939393939393939, 0.6657559198542805, 0.40064102564102566, 0.23529411764705882, 0.3673469387755102, 0.16279069767441862, 0.33962264150943394, 0.3333333333333333, 0.225, 0.3, 0.41228070175438597]\n",
      "Per Class Recall: [0.14606741573033707, 0.45067817509247843, 0.2962085308056872, 0.1518987341772152, 0.18556701030927836, 0.11666666666666667, 0.09836065573770492, 0.16666666666666666, 0.17307692307692307, 0.15894039735099338, 0.15666666666666668]\n",
      "Per Class F1 Score: [0.21311475409836064, 0.5375000000000001, 0.3405994550408719, 0.18461538461538463, 0.24657534246575347, 0.1359223300970874, 0.15254237288135591, 0.2222222222222222, 0.19565217391304346, 0.20779220779220783, 0.2270531400966184]\n",
      "Macro Precision: 0.3487\n",
      "Macro Recall: 0.1910\n",
      "Macro F1 Score: 0.2421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('small_predictions_and_labels.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2260820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.5138, Micro Recall: 0.3145, Micro F1: 0.3901\n",
      "Macro Precision: 0.3487, Macro Recall: 0.1910, Macro F1: 0.2421\n",
      "Weighted Precision: 0.5006, Weighted Recall: 0.3145, Weighted F1: 0.3824\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('small_predictions_and_labels.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc43ed",
   "metadata": {},
   "source": [
    "# whisper-small-chinese-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5042b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.5966, Micro Recall: 0.2846, Micro F1: 0.3854\n",
      "Macro Precision: 0.3955, Macro Recall: 0.1376, Macro F1: 0.1902\n",
      "Weighted Precision: 0.5450, Weighted Recall: 0.2846, Weighted F1: 0.3630\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('predictions_and_labels_small-chinese_base.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525fb604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Precision: [0.47058823529411764, 0.701417004048583, 0.4404332129963899, 0.23076923076923078, 0.4189189189189189, 0.15384615384615385, 0.35, 0.4, 0.25, 0.40229885057471265, 0.532258064516129]\n",
      "Per Class Recall: [0.0898876404494382, 0.4272503082614057, 0.2890995260663507, 0.0379746835443038, 0.15979381443298968, 0.011111111111111112, 0.07650273224043716, 0.041666666666666664, 0.038461538461538464, 0.23178807947019867, 0.11]\n",
      "Per Class F1 Score: [0.1509433962264151, 0.5310344827586208, 0.3490701001430615, 0.06521739130434784, 0.23134328358208953, 0.020725388601036274, 0.12556053811659193, 0.07547169811320754, 0.06666666666666668, 0.2941176470588235, 0.18232044198895028]\n",
      "Macro Precision: 0.3955\n",
      "Macro Recall: 0.1376\n",
      "Macro F1 Score: 0.1902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('predictions_and_labels_small-chinese_base.csv')\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7429d7",
   "metadata": {},
   "source": [
    "# Whisper-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4682925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Precision: [0.4166666666666667, 0.663023679417122, 0.4197183098591549, 0.24, 0.37962962962962965, 0.23333333333333334, 0.48214285714285715, 0.4166666666666667, 0.14705882352941177, 0.43956043956043955, 0.44696969696969696]\n",
      "Per Class Recall: [0.16853932584269662, 0.44882860665844637, 0.35308056872037913, 0.1518987341772152, 0.211340206185567, 0.11666666666666667, 0.14754098360655737, 0.20833333333333334, 0.09615384615384616, 0.26490066225165565, 0.19666666666666666]\n",
      "Per Class F1 Score: [0.24, 0.5352941176470589, 0.38352638352638346, 0.18604651162790697, 0.271523178807947, 0.15555555555555559, 0.22594142259414224, 0.2777777777777778, 0.11627906976744186, 0.3305785123966942, 0.2731481481481482]\n",
      "Macro Precision: 0.3895\n",
      "Macro Recall: 0.2149\n",
      "Macro F1 Score: 0.2723\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'predictions_and_labels_medium.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e927b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.5338, Micro Recall: 0.3334, Micro F1: 0.4105\n",
      "Macro Precision: 0.3895, Macro Recall: 0.2149, Macro F1: 0.2723\n",
      "Weighted Precision: 0.5243, Weighted Recall: 0.3334, Weighted F1: 0.4034\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d8195",
   "metadata": {},
   "source": [
    "# Whisper-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7dcf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Precision: [0.0, 0.7969348659003831, 0.6, 0.0, 0.6666666666666666, 0.0, 0.8, 0.0, 0.0, 0.0, 0.8]\n",
      "Per Class Recall: [0.0, 0.2564734895191122, 0.15639810426540285, 0.0, 0.030927835051546393, 0.0, 0.02185792349726776, 0.0, 0.0, 0.0, 0.02666666666666667]\n",
      "Per Class F1 Score: [0.0, 0.3880597014925373, 0.24812030075187969, 0.0, 0.05911330049261084, 0.0, 0.0425531914893617, 0.0, 0.0, 0.0, 0.05161290322580646]\n",
      "Macro Precision: 0.3331\n",
      "Macro Recall: 0.0448\n",
      "Macro F1 Score: 0.0718\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'predictions_and_labels_large.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497874a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.7622, Micro Recall: 0.1506, Micro F1: 0.2515\n",
      "Macro Precision: 0.3331, Macro Recall: 0.0448, Macro F1: 0.0718\n",
      "Weighted Precision: 0.6210, Weighted Recall: 0.1506, Weighted F1: 0.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855b30a",
   "metadata": {},
   "source": [
    "# wav2vec2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7256ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Precision: [0.26666666666666666, 0.7261363636363637, 0.5371428571428571, 0.0, 0.42, 0.2857142857142857, 0.28888888888888886, 0.0, 0.2222222222222222, 0.4, 0.6333333333333333]\n",
      "Per Class Recall: [0.0449438202247191, 0.39395807644882863, 0.22274881516587677, 0.0, 0.10824742268041238, 0.011111111111111112, 0.07103825136612021, 0.0, 0.038461538461538464, 0.013245033112582781, 0.06333333333333334]\n",
      "Per Class F1 Score: [0.07692307692307691, 0.5107913669064749, 0.3149078726968174, 0.0, 0.1721311475409836, 0.0213903743315508, 0.11403508771929825, 0.0, 0.0655737704918033, 0.02564102564102564, 0.11515151515151516]\n",
      "Macro Precision: 0.3436\n",
      "Macro Recall: 0.0879\n",
      "Macro F1 Score: 0.1288\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'predictions_and_labels_wav2vec2.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46ecad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.6535, Micro Recall: 0.2398, Micro F1: 0.3508\n",
      "Macro Precision: 0.3436, Macro Recall: 0.0879, Macro F1: 0.1288\n",
      "Weighted Precision: 0.5650, Weighted Recall: 0.2398, Weighted F1: 0.3217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d82af9",
   "metadata": {},
   "source": [
    "# hubert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a08398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Precision: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Per Class Recall: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Per Class F1 Score: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Macro Precision: 0.0000\n",
      "Macro Recall: 0.0000\n",
      "Macro F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'predictions_and_labels_hubert.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import ast  # 用于解析字符串形式的列表\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(ast.literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(ast.literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算每个类别的指标\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# 有多少个标签类别\n",
    "num_labels = actual_labels.shape[1]\n",
    "\n",
    "for i in range(num_labels):\n",
    "    class_precision = precision_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_recall = recall_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    class_f1 = f1_score(actual_labels[:, i], predictions[:, i], zero_division=0)\n",
    "    \n",
    "    precisions.append(class_precision)\n",
    "    recalls.append(class_recall)\n",
    "    f1s.append(class_f1)\n",
    "\n",
    "# 宏平均\n",
    "macro_precision = np.mean(precisions)\n",
    "macro_recall = np.mean(recalls)\n",
    "macro_f1 = np.mean(f1s)\n",
    "\n",
    "# 打印每个类别的指标和宏平均\n",
    "print(\"Per Class Precision:\", precisions)\n",
    "print(\"Per Class Recall:\", recalls)\n",
    "print(\"Per Class F1 Score:\", f1s)\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a77f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.0000, Micro Recall: 0.0000, Micro F1: 0.0000\n",
      "Macro Precision: 0.0000, Macro Recall: 0.0000, Macro F1: 0.0000\n",
      "Weighted Precision: 0.0000, Weighted Recall: 0.0000, Weighted F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user416/.conda/envs/songcw/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 将字符串转换为列表\n",
    "df['Predictions'] = df['Predictions'].apply(literal_eval)\n",
    "df['Actual Labels'] = df['Actual Labels'].apply(literal_eval)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "predictions = np.array(df['Predictions'].tolist())\n",
    "actual_labels = np.array(df['Actual Labels'].tolist())\n",
    "\n",
    "# 计算指标\n",
    "# Micro\n",
    "precision_micro = precision_score(actual_labels, predictions, average='micro')\n",
    "recall_micro = recall_score(actual_labels, predictions, average='micro')\n",
    "f1_micro = f1_score(actual_labels, predictions, average='micro')\n",
    "\n",
    "# Macro\n",
    "precision_macro = precision_score(actual_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(actual_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(actual_labels, predictions, average='macro')\n",
    "\n",
    "# Weighted\n",
    "precision_weighted = precision_score(actual_labels, predictions, average='weighted')\n",
    "recall_weighted = recall_score(actual_labels, predictions, average='weighted')\n",
    "f1_weighted = f1_score(actual_labels, predictions, average='weighted')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Micro Precision: {:.4f}, Micro Recall: {:.4f}, Micro F1: {:.4f}\".format(precision_micro, recall_micro, f1_micro))\n",
    "print(\"Macro Precision: {:.4f}, Macro Recall: {:.4f}, Macro F1: {:.4f}\".format(precision_macro, recall_macro, f1_macro))\n",
    "print(\"Weighted Precision: {:.4f}, Weighted Recall: {:.4f}, Weighted F1: {:.4f}\".format(precision_weighted, recall_weighted, f1_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74339d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "songcw",
   "language": "python",
   "name": "songcw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
